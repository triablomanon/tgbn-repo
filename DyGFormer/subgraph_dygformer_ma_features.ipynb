{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/triablomanon/tgbn-project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR00oJpPe96l",
        "outputId": "5d35d0e4-736f-4eb4-be9a-4cb7dc842552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tgbn-project'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 79 (delta 44), reused 72 (delta 37), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (79/79), 90.13 KiB | 4.10 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tgbn-project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpUD8vT2fExh",
        "outputId": "3fe89d1e-82ac-4c9f-bdb0-f60409155e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tgbn-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEK2xbcoNDOk",
        "outputId": "98266272-77c4-40e7-806d-689373085864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/tgbn_cache\n",
        "!ln -s /content/drive/MyDrive/tgbn_cache saved_labeled_node_interaction_indices"
      ],
      "metadata": {
        "id": "C_Z1raMrNMtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjEsNz94fBj4",
        "outputId": "c1ed802e-0de0-4ff1-c37c-baf32a304561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting modules\n",
            "  Downloading modules-1.0.0.tar.gz (525 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: modules\n",
            "  Building wheel for modules (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modules: filename=modules-1.0.0-py3-none-any.whl size=1198 sha256=de758451266e09cca7cc2a929118f622b27cd39556c464ee74de4a1c17eb4c3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/d4/b1/0cfa622e63b93ac1efbca7715a3042d0ed8494204310a31a0f\n",
            "Successfully built modules\n",
            "Installing collected packages: modules\n",
            "Successfully installed modules-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas -q\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install torch-geometric -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install py-tgb -q\n",
        "!pip install modules\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dygformer/test_labels.py\n",
        "# The output of this cell shows us that labels are a probability distribution over the music genres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jVvsEUDL5pn",
        "outputId": "9d793c02-1804-401f-dd81-9966c906c0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tgbn-genre dataset...\n",
            "[################################] 150456/150456 - 00:00:45\n",
            "17858396it [01:00, 293819.13it/s]\n",
            "2741936it [00:06, 452059.22it/s]\n",
            "\n",
            "=== Dataset Info ===\n",
            "Number of classes (genres): 513\n",
            "Number of timestamps with labels: 1579\n",
            "Total labeled nodes (across all timestamps): 256493\n",
            "\n",
            "=== Examining First 10 Labels ===\n",
            "\n",
            "Label #1:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 533\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 33\n",
            "  Active genre indices: [ 1  2  4  5  7  8 18 20 22 24 29 43 49 51 53 54 56 58 66 72]...\n",
            "  Label values at active positions: [0.0362972  0.00566081 0.11384996 0.0668751  0.01886783 0.00524037\n",
            " 0.01665354 0.01200711 0.04967586 0.01532975 0.0112734  0.01434797\n",
            " 0.00808153 0.17058364 0.08572021 0.01091456 0.07216231 0.00436233\n",
            " 0.02146456 0.0268307 ]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #2:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 519\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 12\n",
            "  Active genre indices: [  2   5  16  18  20  23  46  49  93  94 192 194]...\n",
            "  Label values at active positions: [0.46779073 0.02834757 0.05699552 0.06169765 0.02659382 0.03989072\n",
            " 0.03335008 0.13573483 0.02467906 0.01233953 0.08226353 0.03031695]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #3:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 525\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 60\n",
            "  Active genre indices: [ 2  4  5  6  8 12 14 16 20 21 23 24 29 37 39 46 49 51 55 56]...\n",
            "  Label values at active positions: [0.00310839 0.02735416 0.10621209 0.00063637 0.04076359 0.00306685\n",
            " 0.06567606 0.00414209 0.00129809 0.25243761 0.00158291 0.00670945\n",
            " 0.02700648 0.01745474 0.00202412 0.04246831 0.04353274 0.00236852\n",
            " 0.03332522 0.03032769]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #4:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 541\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 37\n",
            "  Active genre indices: [ 1  2  4  5  6  7  8 20 23 24 29 38 40 42 46 51 60 64 65 68]...\n",
            "  Label values at active positions: [0.00890608 0.0617295  0.14398663 0.108526   0.04871381 0.02488887\n",
            " 0.03656781 0.00495479 0.03635205 0.01555428 0.0705792  0.04591798\n",
            " 0.00288507 0.00495479 0.0080348  0.01145621 0.02084082 0.00437188\n",
            " 0.02972875 0.00743219]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #5:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 521\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 42\n",
            "  Active genre indices: [ 1  2  3  4  5  6  7  8  9 13 17 18 19 20 22 23 24 27 28 32]...\n",
            "  Label values at active positions: [0.01237811 0.32894661 0.00817291 0.08083148 0.02058515 0.00146247\n",
            " 0.00142338 0.01697035 0.0015651  0.0011655  0.03647512 0.06113685\n",
            " 0.03056842 0.04075523 0.02321197 0.01861468 0.05743711 0.01750959\n",
            " 0.01464499 0.01313438]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #6:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 520\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 45\n",
            "  Active genre indices: [ 1  2  3  4  5  6  7  8  9 13 14 16 21 22 24 29 35 37 41 43]...\n",
            "  Label values at active positions: [0.04648148 0.00391505 0.01950898 0.15425834 0.14352061 0.04931462\n",
            " 0.03300601 0.09310186 0.00079206 0.00391505 0.0595794  0.00391505\n",
            " 0.0075276  0.00340752 0.01562065 0.10108498 0.00951303 0.00426281\n",
            " 0.00808447 0.05727842]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #7:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 543\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 33\n",
            "  Active genre indices: [  1   2   4   7   8   9  18  20  21  22  23  24  42  44  51  53  56  57\n",
            "  74 100]...\n",
            "  Label values at active positions: [0.01982406 0.01867751 0.13156254 0.00796576 0.00997566 0.0175616\n",
            " 0.01618269 0.01530264 0.012089   0.15763314 0.00493177 0.00676984\n",
            " 0.01093767 0.00949677 0.06984878 0.01122934 0.08903684 0.00802232\n",
            " 0.00524191 0.00315825]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #8:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 527\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 47\n",
            "  Active genre indices: [ 1  3  4  5  6  7  8 14 16 18 20 21 22 23 29 35 37 41 43 44]...\n",
            "  Label values at active positions: [0.04531388 0.03198983 0.07882279 0.29767767 0.0388824  0.0055574\n",
            " 0.00713637 0.0105727  0.00770455 0.00816115 0.01864715 0.07363758\n",
            " 0.02455315 0.00155104 0.025172   0.0078198  0.01527521 0.00242703\n",
            " 0.0476933  0.01150712]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #9:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 518\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 51\n",
            "  Active genre indices: [ 1  2  3  4  5  6  7  8  9 13 14 15 16 20 21 22 23 24 43 44]...\n",
            "  Label values at active positions: [0.06556438 0.02842642 0.01173242 0.12313985 0.1171237  0.04748117\n",
            " 0.02360636 0.03809128 0.00145769 0.01007979 0.08571178 0.01417081\n",
            " 0.01509987 0.03199727 0.02747009 0.05278887 0.02021508 0.01818526\n",
            " 0.00974154 0.0099222 ]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "Label #10:\n",
            "  Timestamp: 1108443600\n",
            "  Node ID: 531\n",
            "  Label shape: (513,)\n",
            "  Number of active genres: 49\n",
            "  Active genre indices: [ 1  2  4  5  6  7  8  9 14 16 21 22 23 29 34 37 44 50 53 54]...\n",
            "  Label values at active positions: [0.01132512 0.02152627 0.24159307 0.0308558  0.00729158 0.02346155\n",
            " 0.04403272 0.02491431 0.02227177 0.01051296 0.01223084 0.15023653\n",
            " 0.00596932 0.05281301 0.00364235 0.00239181 0.01738517 0.00527605\n",
            " 0.03693459 0.00921433]\n",
            "  Sum of label: 1.00\n",
            "\n",
            "=== Label Statistics Across Dataset ===\n",
            "Average number of active genres per label: 10.69\n",
            "Min number of active genres: 1\n",
            "Max number of active genres: 152\n",
            "Median number of active genres: 8\n",
            "\n",
            "Average sum of label values: 1.00\n",
            "Label sum range: [1.00, 1.00]\n",
            "\n",
            "=== Distribution of Active Genres ===\n",
            "  1 active genres: 17061 labels (6.7%)\n",
            "  2 active genres: 19481 labels (7.6%)\n",
            "  3 active genres: 19012 labels (7.4%)\n",
            "  4 active genres: 18015 labels (7.0%)\n",
            "  5 active genres: 17016 labels (6.6%)\n",
            "  6 active genres: 15834 labels (6.2%)\n",
            "  7 active genres: 14717 labels (5.7%)\n",
            "  8 active genres: 13426 labels (5.2%)\n",
            "  9 active genres: 12307 labels (4.8%)\n",
            "  10 active genres: 11341 labels (4.4%)\n",
            "\n",
            "=== How NDCG@10 Works ===\n",
            "NDCG@10 means:\n",
            "  - Model predicts probabilities for all 513 genres\n",
            "  - We take the TOP 10 predicted genres (highest probabilities)\n",
            "  - We compare these top 10 to the TRUE labels\n",
            "  - NDCG measures how well the ranking matches (higher score = better)\n",
            "\n",
            "Example:\n",
            "  True labels: Genres [5, 12, 89] are active\n",
            "  Model predicts top 10: [5, 89, 12, 100, 3, ...]\n",
            "  NDCG@10 would be high because all 3 true genres are in top 10\n",
            "  and they're ranked highly (positions 1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DyGFormer"
      ],
      "metadata": {
        "id": "pI8xgnYwY2IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python dygformer/train_node_classification.py \\\n",
        "    --dataset_name tgbn-genre \\\n",
        "    --model_name DyGFormer \\\n",
        "    --load_best_configs \\\n",
        "    --subset_fraction 0.1 \\\n",
        "    --timestamp_threshold 1135778006 \\\n",
        "    --filter_seed 42 \\\n",
        "    --num_runs 5 \\\n",
        "    --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmoCxgsCihz_",
        "outputId": "1a7f3b78-9986-4115-e1e9-ae3ba3b6cd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After filtering: 1667637 interactions (from 17858395 original)\n",
            "Selected 99 source nodes out of 992 (10.0%)\n",
            "Set edge IDs to array indices: [0, 1667636]\n",
            "100% 1579/1579 [00:00<00:00, 1993.43it/s]\n",
            "Loaded preprocessed cache from ./saved_labeled_node_interaction_indices/tgbn-genre_subset0.1_ts1135778006.0_seed42.npy\n",
            "100% 25461/25461 [00:00<00:00, 164097.20it/s]\n",
            "[FILTERED] Re-indexed 609 nodes:\n",
            "  - src_node_ids from [523, 1490] to [510, 608]\n",
            "  - dst_node_ids from [0, 512] to [0, 509]\n",
            "[DEBUG] edge_ids range: [1, 1667637]\n",
            "[DEBUG] edge_raw_features shape: (1667638, 1), max valid index: 1667637\n",
            "[DEBUG] src_node_ids range: [511, 609]\n",
            "[DEBUG] node_raw_features shape: (611, 1), max valid index: 610\n",
            "The dataset has 1667637 interactions, involving 609 different nodes\n",
            "The training dataset has 1185239 interactions, involving 592 different nodes\n",
            "The validation dataset has 240194 interactions, involving 575 different nodes\n",
            "The test dataset has 242204 interactions, involving 581 different nodes\n",
            "INFO:root:********** Run 1 starts. **********\n",
            "INFO:root:configuration is Namespace(dataset_name='tgbn-genre', batch_size=200, model_name='DyGFormer', gpu=0, num_neighbors=20, sample_neighbor_strategy='recent', time_scaling_factor=1e-06, num_walk_heads=8, num_heads=2, num_layers=2, walk_length=1, time_gap=2000, time_feat_dim=100, position_feat_dim=172, output_dim=172, moving_average_window_size=7, patch_size=8, channel_embedding_dim=50, max_input_sequence_length=256, learning_rate=0.0001, dropout=0.1, num_epochs=100, optimizer='Adam', weight_decay=0.0, patience=20, num_runs=5, test_interval_epochs=10, load_best_configs=True, subset_fraction=0.1, timestamp_threshold=1135778006.0, filter_seed=42, device='cuda:0', seed=0, save_model_name='DyGFormer_seed0')\n",
            "INFO:root:model -> Sequential(\n",
            "  (0): DyGFormer(\n",
            "    (time_encoder): TimeEncoder(\n",
            "      (w): Linear(in_features=1, out_features=100, bias=True)\n",
            "    )\n",
            "    (neighbor_co_occurrence_encoder): NeighborCooccurrenceEncoder(\n",
            "      (neighbor_co_occurrence_encode_layer): Sequential(\n",
            "        (0): Linear(in_features=1, out_features=50, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (projection_layer): ModuleDict(\n",
            "      (node): Linear(in_features=8, out_features=50, bias=True)\n",
            "      (edge): Linear(in_features=8, out_features=50, bias=True)\n",
            "      (time): Linear(in_features=800, out_features=50, bias=True)\n",
            "      (neighbor_co_occurrence): Linear(in_features=400, out_features=50, bias=True)\n",
            "    )\n",
            "    (transformers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoder(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear_layers): ModuleList(\n",
            "          (0): Linear(in_features=200, out_features=800, bias=True)\n",
            "          (1): Linear(in_features=800, out_features=200, bias=True)\n",
            "        )\n",
            "        (norm_layers): ModuleList(\n",
            "          (0-1): 2 x LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_layer): Linear(in_features=200, out_features=172, bias=True)\n",
            "  )\n",
            "  (1): MLPClassifier(\n",
            "    (fc1): Linear(in_features=172, out_features=80, bias=True)\n",
            "    (fc2): Linear(in_features=80, out_features=10, bias=True)\n",
            "    (fc3): Linear(in_features=10, out_features=513, bias=True)\n",
            "    (act): ReLU()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "INFO:root:model name: DyGFormer, #parameters: 4335660 B, 4234.04296875 KB, 4.134807586669922 MB.\n",
            "Epoch: 1, train for the 5919-th batch, train loss: 4.7527360916137695: 100%|████████| 5927/5927 [17:02<00:00,  5.80it/s]\n",
            "100% 933/933 [00:03<00:00, 240.34it/s]\n",
            "val for the 1201-th batch, loss: 4.864763259887695: 100%|███████████████████████████| 1201/1201 [02:03<00:00,  9.72it/s]\n",
            "100% 163/163 [00:00<00:00, 274.15it/s]\n",
            "INFO:root:Epoch: 1, learning rate: 0.0001, train loss: 5.2143\n",
            "INFO:root:train ndcg, 0.2083\n",
            "INFO:root:validate loss: 4.7215\n",
            "INFO:root:validate ndcg, 0.3206\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 2, train for the 5919-th batch, train loss: 4.636064529418945: 100%|█████████| 5927/5927 [16:48<00:00,  5.88it/s]\n",
            "100% 933/933 [00:02<00:00, 311.49it/s]\n",
            "val for the 1201-th batch, loss: 4.873241424560547: 100%|███████████████████████████| 1201/1201 [02:02<00:00,  9.83it/s]\n",
            "100% 163/163 [00:00<00:00, 286.26it/s]\n",
            "INFO:root:Epoch: 2, learning rate: 0.0001, train loss: 4.6242\n",
            "INFO:root:train ndcg, 0.3431\n",
            "INFO:root:validate loss: 4.6195\n",
            "INFO:root:validate ndcg, 0.3459\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 3, train for the 5919-th batch, train loss: 4.607203960418701: 100%|█████████| 5927/5927 [16:41<00:00,  5.92it/s]\n",
            "100% 933/933 [00:03<00:00, 300.42it/s]\n",
            "val for the 1201-th batch, loss: 4.894079685211182: 100%|███████████████████████████| 1201/1201 [02:00<00:00,  9.96it/s]\n",
            "100% 163/163 [00:00<00:00, 283.24it/s]\n",
            "INFO:root:Epoch: 3, learning rate: 0.0001, train loss: 4.5756\n",
            "INFO:root:train ndcg, 0.3550\n",
            "INFO:root:validate loss: 4.6099\n",
            "INFO:root:validate ndcg, 0.3479\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 4, train for the 5919-th batch, train loss: 4.643989562988281: 100%|█████████| 5927/5927 [16:45<00:00,  5.90it/s]\n",
            "100% 933/933 [00:03<00:00, 289.44it/s]\n",
            "val for the 1201-th batch, loss: 4.908525466918945: 100%|███████████████████████████| 1201/1201 [02:02<00:00,  9.81it/s]\n",
            "100% 163/163 [00:00<00:00, 282.37it/s]\n",
            "INFO:root:Epoch: 4, learning rate: 0.0001, train loss: 4.5509\n",
            "INFO:root:train ndcg, 0.3610\n",
            "INFO:root:validate loss: 4.6088\n",
            "INFO:root:validate ndcg, 0.3488\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 5, train for the 5919-th batch, train loss: 4.691952705383301: 100%|█████████| 5927/5927 [16:43<00:00,  5.90it/s]\n",
            "100% 933/933 [00:03<00:00, 310.34it/s]\n",
            "val for the 1201-th batch, loss: 4.913886070251465: 100%|███████████████████████████| 1201/1201 [02:01<00:00,  9.87it/s]\n",
            "100% 163/163 [00:00<00:00, 201.46it/s]\n",
            "INFO:root:Epoch: 5, learning rate: 0.0001, train loss: 4.5399\n",
            "INFO:root:train ndcg, 0.3644\n",
            "INFO:root:validate loss: 4.6091\n",
            "INFO:root:validate ndcg, 0.3482\n",
            "Epoch: 6, train for the 5919-th batch, train loss: 4.558282852172852: 100%|█████████| 5927/5927 [16:45<00:00,  5.89it/s]\n",
            "100% 933/933 [00:03<00:00, 304.93it/s]\n",
            "val for the 1201-th batch, loss: 4.910384654998779: 100%|███████████████████████████| 1201/1201 [01:59<00:00, 10.01it/s]\n",
            "100% 163/163 [00:00<00:00, 295.48it/s]\n",
            "INFO:root:Epoch: 6, learning rate: 0.0001, train loss: 4.5345\n",
            "INFO:root:train ndcg, 0.3654\n",
            "INFO:root:validate loss: 4.6101\n",
            "INFO:root:validate ndcg, 0.3495\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 7, train for the 5919-th batch, train loss: 4.615325927734375: 100%|█████████| 5927/5927 [16:26<00:00,  6.01it/s]\n",
            "100% 933/933 [00:02<00:00, 321.33it/s]\n",
            "val for the 1201-th batch, loss: 4.92043399810791: 100%|████████████████████████████| 1201/1201 [01:57<00:00, 10.18it/s]\n",
            "100% 163/163 [00:00<00:00, 283.04it/s]\n",
            "INFO:root:Epoch: 7, learning rate: 0.0001, train loss: 4.5260\n",
            "INFO:root:train ndcg, 0.3674\n",
            "INFO:root:validate loss: 4.6116\n",
            "INFO:root:validate ndcg, 0.3501\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 8, train for the 5919-th batch, train loss: 4.58794641494751: 100%|██████████| 5927/5927 [16:25<00:00,  6.02it/s]\n",
            "100% 933/933 [00:02<00:00, 326.48it/s]\n",
            "val for the 1201-th batch, loss: 4.920782089233398: 100%|███████████████████████████| 1201/1201 [02:00<00:00,  9.96it/s]\n",
            "100% 163/163 [00:00<00:00, 287.96it/s]\n",
            "INFO:root:Epoch: 8, learning rate: 0.0001, train loss: 4.5221\n",
            "INFO:root:train ndcg, 0.3688\n",
            "INFO:root:validate loss: 4.6114\n",
            "INFO:root:validate ndcg, 0.3508\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 9, train for the 5919-th batch, train loss: 4.612510681152344: 100%|█████████| 5927/5927 [16:33<00:00,  5.97it/s]\n",
            "100% 933/933 [00:02<00:00, 325.16it/s]\n",
            "val for the 1201-th batch, loss: 4.912398338317871: 100%|███████████████████████████| 1201/1201 [01:58<00:00, 10.17it/s]\n",
            "100% 163/163 [00:00<00:00, 289.59it/s]\n",
            "INFO:root:Epoch: 9, learning rate: 0.0001, train loss: 4.5132\n",
            "INFO:root:train ndcg, 0.3710\n",
            "INFO:root:validate loss: 4.6117\n",
            "INFO:root:validate ndcg, 0.3510\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 10, train for the 5919-th batch, train loss: 4.575305938720703: 100%|████████| 5927/5927 [16:27<00:00,  6.00it/s]\n",
            "100% 933/933 [00:02<00:00, 323.76it/s]\n",
            "val for the 1201-th batch, loss: 4.90866231918335: 100%|████████████████████████████| 1201/1201 [01:57<00:00, 10.23it/s]\n",
            "100% 163/163 [00:00<00:00, 294.30it/s]\n",
            "INFO:root:Epoch: 10, learning rate: 0.0001, train loss: 4.5113\n",
            "INFO:root:train ndcg, 0.3711\n",
            "INFO:root:validate loss: 4.6118\n",
            "INFO:root:validate ndcg, 0.3507\n",
            "test for the 1203-th batch, loss: 5.444032669067383: 100%|██████████████████████████| 1212/1212 [01:55<00:00, 10.50it/s]\n",
            "100% 166/166 [00:00<00:00, 313.78it/s]\n",
            "INFO:root:test loss: 4.6390\n",
            "INFO:root:test ndcg, 0.3483\n",
            "Epoch: 11, train for the 5919-th batch, train loss: 4.594209671020508: 100%|████████| 5927/5927 [16:31<00:00,  5.98it/s]\n",
            "100% 933/933 [00:02<00:00, 311.29it/s]\n",
            "val for the 1201-th batch, loss: 4.906815528869629: 100%|███████████████████████████| 1201/1201 [01:59<00:00, 10.06it/s]\n",
            "100% 163/163 [00:00<00:00, 282.37it/s]\n",
            "INFO:root:Epoch: 11, learning rate: 0.0001, train loss: 4.5066\n",
            "INFO:root:train ndcg, 0.3730\n",
            "INFO:root:validate loss: 4.6127\n",
            "INFO:root:validate ndcg, 0.3524\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 12, train for the 5919-th batch, train loss: 4.637196063995361: 100%|████████| 5927/5927 [16:26<00:00,  6.01it/s]\n",
            "100% 933/933 [00:03<00:00, 274.44it/s]\n",
            "val for the 1201-th batch, loss: 4.909733772277832: 100%|███████████████████████████| 1201/1201 [01:58<00:00, 10.15it/s]\n",
            "100% 163/163 [00:00<00:00, 291.88it/s]\n",
            "INFO:root:Epoch: 12, learning rate: 0.0001, train loss: 4.5060\n",
            "INFO:root:train ndcg, 0.3731\n",
            "INFO:root:validate loss: 4.6124\n",
            "INFO:root:validate ndcg, 0.3501\n",
            "Epoch: 13, train for the 5919-th batch, train loss: 4.542048454284668: 100%|████████| 5927/5927 [16:22<00:00,  6.03it/s]\n",
            "100% 933/933 [00:02<00:00, 325.86it/s]\n",
            "val for the 1201-th batch, loss: 4.9105224609375: 100%|█████████████████████████████| 1201/1201 [01:56<00:00, 10.29it/s]\n",
            "100% 163/163 [00:00<00:00, 295.83it/s]\n",
            "INFO:root:Epoch: 13, learning rate: 0.0001, train loss: 4.4956\n",
            "INFO:root:train ndcg, 0.3752\n",
            "INFO:root:validate loss: 4.6124\n",
            "INFO:root:validate ndcg, 0.3506\n",
            "Epoch: 14, train for the 5919-th batch, train loss: 4.574064254760742: 100%|████████| 5927/5927 [16:24<00:00,  6.02it/s]\n",
            "100% 933/933 [00:02<00:00, 321.15it/s]\n",
            "val for the 1201-th batch, loss: 4.911670207977295: 100%|███████████████████████████| 1201/1201 [01:58<00:00, 10.10it/s]\n",
            "100% 163/163 [00:00<00:00, 285.92it/s]\n",
            "INFO:root:Epoch: 14, learning rate: 0.0001, train loss: 4.4899\n",
            "INFO:root:train ndcg, 0.3754\n",
            "INFO:root:validate loss: 4.6125\n",
            "INFO:root:validate ndcg, 0.3529\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 15, train for the 5919-th batch, train loss: 4.61116886138916: 100%|█████████| 5927/5927 [16:31<00:00,  5.98it/s]\n",
            "100% 933/933 [00:03<00:00, 279.15it/s]\n",
            "val for the 1201-th batch, loss: 4.901109218597412: 100%|███████████████████████████| 1201/1201 [02:00<00:00, 10.01it/s]\n",
            "100% 163/163 [00:00<00:00, 291.58it/s]\n",
            "INFO:root:Epoch: 15, learning rate: 0.0001, train loss: 4.4886\n",
            "INFO:root:train ndcg, 0.3775\n",
            "INFO:root:validate loss: 4.6096\n",
            "INFO:root:validate ndcg, 0.3517\n",
            "Epoch: 16, train for the 5919-th batch, train loss: 4.590173244476318: 100%|████████| 5927/5927 [16:34<00:00,  5.96it/s]\n",
            "100% 933/933 [00:02<00:00, 322.19it/s]\n",
            "val for the 1201-th batch, loss: 4.906452178955078: 100%|███████████████████████████| 1201/1201 [01:57<00:00, 10.25it/s]\n",
            "100% 163/163 [00:00<00:00, 288.05it/s]\n",
            "INFO:root:Epoch: 16, learning rate: 0.0001, train loss: 4.4853\n",
            "INFO:root:train ndcg, 0.3766\n",
            "INFO:root:validate loss: 4.6093\n",
            "INFO:root:validate ndcg, 0.3485\n",
            "Epoch: 17, train for the 5919-th batch, train loss: 4.571086406707764: 100%|████████| 5927/5927 [16:27<00:00,  6.00it/s]\n",
            "100% 933/933 [00:03<00:00, 247.38it/s]\n",
            "val for the 1201-th batch, loss: 4.8955230712890625: 100%|██████████████████████████| 1201/1201 [02:00<00:00, 10.00it/s]\n",
            "100% 163/163 [00:00<00:00, 271.14it/s]\n",
            "INFO:root:Epoch: 17, learning rate: 0.0001, train loss: 4.4824\n",
            "INFO:root:train ndcg, 0.3769\n",
            "INFO:root:validate loss: 4.6102\n",
            "INFO:root:validate ndcg, 0.3520\n",
            "Epoch: 18, train for the 5919-th batch, train loss: 4.565927505493164: 100%|████████| 5927/5927 [16:27<00:00,  6.00it/s]\n",
            "100% 933/933 [00:02<00:00, 312.00it/s]\n",
            "val for the 1201-th batch, loss: 4.89247989654541: 100%|████████████████████████████| 1201/1201 [01:58<00:00, 10.16it/s]\n",
            "100% 163/163 [00:00<00:00, 219.61it/s]\n",
            "INFO:root:Epoch: 18, learning rate: 0.0001, train loss: 4.4782\n",
            "INFO:root:train ndcg, 0.3779\n",
            "INFO:root:validate loss: 4.6092\n",
            "INFO:root:validate ndcg, 0.3488\n",
            "Epoch: 19, train for the 5919-th batch, train loss: 4.685079097747803: 100%|████████| 5927/5927 [16:34<00:00,  5.96it/s]\n",
            "100% 933/933 [00:03<00:00, 247.00it/s]\n",
            "val for the 1201-th batch, loss: 4.889476299285889: 100%|███████████████████████████| 1201/1201 [01:59<00:00, 10.09it/s]\n",
            "100% 163/163 [00:00<00:00, 284.33it/s]\n",
            "INFO:root:Epoch: 19, learning rate: 0.0001, train loss: 4.4734\n",
            "INFO:root:train ndcg, 0.3782\n",
            "INFO:root:validate loss: 4.6054\n",
            "INFO:root:validate ndcg, 0.3528\n",
            "Epoch: 20, train for the 5919-th batch, train loss: 4.534531116485596: 100%|████████| 5927/5927 [16:29<00:00,  5.99it/s]\n",
            "100% 933/933 [00:03<00:00, 270.26it/s]\n",
            "val for the 1201-th batch, loss: 4.896292686462402: 100%|███████████████████████████| 1201/1201 [01:59<00:00, 10.07it/s]\n",
            "100% 163/163 [00:00<00:00, 293.05it/s]\n",
            "INFO:root:Epoch: 20, learning rate: 0.0001, train loss: 4.4703\n",
            "INFO:root:train ndcg, 0.3789\n",
            "INFO:root:validate loss: 4.6062\n",
            "INFO:root:validate ndcg, 0.3524\n",
            "test for the 1203-th batch, loss: 5.424579620361328: 100%|██████████████████████████| 1212/1212 [01:55<00:00, 10.53it/s]\n",
            "100% 166/166 [00:00<00:00, 308.74it/s]\n",
            "INFO:root:test loss: 4.6399\n",
            "INFO:root:test ndcg, 0.3477\n",
            "Epoch: 21, train for the 5919-th batch, train loss: 4.603937149047852: 100%|████████| 5927/5927 [16:31<00:00,  5.98it/s]\n",
            "100% 933/933 [00:02<00:00, 312.13it/s]\n",
            "val for the 1201-th batch, loss: 4.891121864318848: 100%|███████████████████████████| 1201/1201 [01:59<00:00, 10.05it/s]\n",
            "100% 163/163 [00:00<00:00, 179.98it/s]\n",
            "INFO:root:Epoch: 21, learning rate: 0.0001, train loss: 4.4648\n",
            "INFO:root:train ndcg, 0.3791\n",
            "INFO:root:validate loss: 4.6021\n",
            "INFO:root:validate ndcg, 0.3517\n",
            "Epoch: 22, train for the 5919-th batch, train loss: 4.5600810050964355: 100%|███████| 5927/5927 [16:41<00:00,  5.92it/s]\n",
            "100% 933/933 [00:03<00:00, 308.05it/s]\n",
            "val for the 1201-th batch, loss: 4.90082311630249: 100%|████████████████████████████| 1201/1201 [01:59<00:00, 10.02it/s]\n",
            "100% 163/163 [00:00<00:00, 283.75it/s]\n",
            "INFO:root:Epoch: 22, learning rate: 0.0001, train loss: 4.4656\n",
            "INFO:root:train ndcg, 0.3790\n",
            "INFO:root:validate loss: 4.6028\n",
            "INFO:root:validate ndcg, 0.3522\n",
            "Epoch: 23, train for the 5919-th batch, train loss: 4.569627285003662: 100%|████████| 5927/5927 [16:29<00:00,  5.99it/s]\n",
            "100% 933/933 [00:02<00:00, 317.84it/s]\n",
            "val for the 1201-th batch, loss: 4.895298004150391: 100%|███████████████████████████| 1201/1201 [01:59<00:00, 10.01it/s]\n",
            "100% 163/163 [00:00<00:00, 288.30it/s]\n",
            "INFO:root:Epoch: 23, learning rate: 0.0001, train loss: 4.4606\n",
            "INFO:root:train ndcg, 0.3796\n",
            "INFO:root:validate loss: 4.5991\n",
            "INFO:root:validate ndcg, 0.3537\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 24, train for the 5919-th batch, train loss: 4.618171691894531: 100%|████████| 5927/5927 [16:22<00:00,  6.04it/s]\n",
            "100% 933/933 [00:03<00:00, 268.86it/s]\n",
            "val for the 1201-th batch, loss: 4.901939392089844: 100%|███████████████████████████| 1201/1201 [01:55<00:00, 10.37it/s]\n",
            "100% 163/163 [00:00<00:00, 296.72it/s]\n",
            "INFO:root:Epoch: 24, learning rate: 0.0001, train loss: 4.4568\n",
            "INFO:root:train ndcg, 0.3813\n",
            "INFO:root:validate loss: 4.5978\n",
            "INFO:root:validate ndcg, 0.3545\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 25, train for the 5919-th batch, train loss: 4.637293338775635: 100%|████████| 5927/5927 [16:16<00:00,  6.07it/s]\n",
            "100% 933/933 [00:02<00:00, 340.79it/s]\n",
            "val for the 1201-th batch, loss: 4.894812107086182: 100%|███████████████████████████| 1201/1201 [01:58<00:00, 10.16it/s]\n",
            "100% 163/163 [00:00<00:00, 282.48it/s]\n",
            "INFO:root:Epoch: 25, learning rate: 0.0001, train loss: 4.4551\n",
            "INFO:root:train ndcg, 0.3812\n",
            "INFO:root:validate loss: 4.5948\n",
            "INFO:root:validate ndcg, 0.3546\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 26, train for the 5919-th batch, train loss: 4.5290422439575195: 100%|███████| 5927/5927 [16:24<00:00,  6.02it/s]\n",
            "100% 933/933 [00:02<00:00, 329.62it/s]\n",
            "val for the 1201-th batch, loss: 4.904026031494141: 100%|███████████████████████████| 1201/1201 [01:57<00:00, 10.21it/s]\n",
            "100% 163/163 [00:00<00:00, 273.79it/s]\n",
            "INFO:root:Epoch: 26, learning rate: 0.0001, train loss: 4.4513\n",
            "INFO:root:train ndcg, 0.3815\n",
            "INFO:root:validate loss: 4.5938\n",
            "INFO:root:validate ndcg, 0.3559\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 27, train for the 5919-th batch, train loss: 4.557278633117676: 100%|████████| 5927/5927 [16:18<00:00,  6.06it/s]\n",
            "100% 933/933 [00:02<00:00, 331.41it/s]\n",
            "val for the 1201-th batch, loss: 4.9127912521362305: 100%|██████████████████████████| 1201/1201 [01:57<00:00, 10.24it/s]\n",
            "100% 163/163 [00:00<00:00, 264.48it/s]\n",
            "INFO:root:Epoch: 27, learning rate: 0.0001, train loss: 4.4480\n",
            "INFO:root:train ndcg, 0.3828\n",
            "INFO:root:validate loss: 4.5888\n",
            "INFO:root:validate ndcg, 0.3557\n",
            "Epoch: 28, train for the 5919-th batch, train loss: 4.516269683837891: 100%|████████| 5927/5927 [16:23<00:00,  6.02it/s]\n",
            "100% 933/933 [00:02<00:00, 314.08it/s]\n",
            "val for the 1201-th batch, loss: 4.908273220062256: 100%|███████████████████████████| 1201/1201 [01:58<00:00, 10.10it/s]\n",
            "100% 163/163 [00:00<00:00, 261.62it/s]\n",
            "INFO:root:Epoch: 28, learning rate: 0.0001, train loss: 4.4464\n",
            "INFO:root:train ndcg, 0.3821\n",
            "INFO:root:validate loss: 4.5874\n",
            "INFO:root:validate ndcg, 0.3561\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 29, train for the 5919-th batch, train loss: 4.5641584396362305: 100%|███████| 5927/5927 [16:30<00:00,  5.98it/s]\n",
            "100% 933/933 [00:03<00:00, 307.20it/s]\n",
            "val for the 1201-th batch, loss: 4.912259578704834: 100%|███████████████████████████| 1201/1201 [01:59<00:00, 10.09it/s]\n",
            "100% 163/163 [00:00<00:00, 290.70it/s]\n",
            "INFO:root:Epoch: 29, learning rate: 0.0001, train loss: 4.4439\n",
            "INFO:root:train ndcg, 0.3832\n",
            "INFO:root:validate loss: 4.5850\n",
            "INFO:root:validate ndcg, 0.3559\n",
            "Epoch: 30, train for the 5919-th batch, train loss: 4.5113935470581055: 100%|███████| 5927/5927 [16:30<00:00,  5.99it/s]\n",
            "100% 933/933 [00:03<00:00, 279.79it/s]\n",
            "val for the 1201-th batch, loss: 4.922486305236816: 100%|███████████████████████████| 1201/1201 [02:00<00:00, 10.00it/s]\n",
            "100% 163/163 [00:00<00:00, 198.53it/s]\n",
            "INFO:root:Epoch: 30, learning rate: 0.0001, train loss: 4.4372\n",
            "INFO:root:train ndcg, 0.3832\n",
            "INFO:root:validate loss: 4.5833\n",
            "INFO:root:validate ndcg, 0.3570\n",
            "test for the 1203-th batch, loss: 5.3616533279418945: 100%|█████████████████████████| 1212/1212 [01:54<00:00, 10.54it/s]\n",
            "100% 166/166 [00:00<00:00, 309.91it/s]\n",
            "INFO:root:test loss: 4.6203\n",
            "INFO:root:test ndcg, 0.3529\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 31, train for the 2506-th batch, train loss: 5.177792072296143:  42%|███▍    | 2506/5927 [06:56<04:16, 13.36it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x13cc21f067a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1196, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1265, in close\n",
            "    def close(self):\n",
            "\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DyGLib_TGB/train_node_classification.py\", line 216, in <module>\n",
            "    model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,\n",
            "  File \"/content/DyGLib_TGB/models/DyGFormer.py\", line 107, in compute_src_dst_node_temporal_embeddings\n",
            "    self.neighbor_co_occurrence_encoder(src_padded_nodes_neighbor_ids=src_padded_nodes_neighbor_ids,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DyGLib_TGB/models/DyGFormer.py\", line 406, in forward\n",
            "    src_padded_nodes_appearances, dst_padded_nodes_appearances = self.count_nodes_appearances(src_padded_nodes_neighbor_ids=src_padded_nodes_neighbor_ids,\n",
            "                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DyGLib_TGB/models/DyGFormer.py\", line 374, in count_nodes_appearances\n",
            "    src_padded_node_neighbor_counts_in_dst = torch.from_numpy(src_padded_node_neighbor_ids.copy()).apply_(lambda neighbor_id: dst_mapping_dict.get(neighbor_id, 0.0)).float().to(self.device)\n",
            "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DyGLib_TGB/models/DyGFormer.py\", line 374, in <lambda>\n",
            "    src_padded_node_neighbor_counts_in_dst = torch.from_numpy(src_padded_node_neighbor_ids.copy()).apply_(lambda neighbor_id: dst_mapping_dict.get(neighbor_id, 0.0)).float().to(self.device)\n",
            "\n",
            "KeyboardInterrupt\n",
            "Epoch: 31, train for the 2506-th batch, train loss: 5.177792072296143:  42%|███▍    | 2506/5927 [06:56<09:28,  6.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DyGFormer with MA Features"
      ],
      "metadata": {
        "id": "SAFb5r-cY8fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python dygformer/train_node_classification.py \\\n",
        "    --dataset_name tgbn-genre \\\n",
        "    --model_name DyGFormer \\\n",
        "    --gpu 0 \\\n",
        "    --load_best_configs \\\n",
        "    --use_ma_features \\\n",
        "    --ma_window_size 7 \\\n",
        "    --subset_fraction 0.1 \\\n",
        "    --timestamp_threshold 1135778006 \\\n",
        "    --filter_seed 42 \\\n",
        "    --num_epochs 100 \\\n",
        "    --patience 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_MAPhrnZ9_O",
        "outputId": "60959e70-6d41-489e-b8f8-cb966f247e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[################################] 150456/150456 - 00:00:44\n",
            "17858396it [01:03, 281044.37it/s]\n",
            "2741936it [00:07, 373423.85it/s]\n",
            "After filtering: 1667637 interactions (from 17858395 original)\n",
            "Selected 99 source nodes out of 992 (10.0%)\n",
            "Set edge IDs to array indices: [0, 1667636]\n",
            "100% 1579/1579 [00:00<00:00, 2074.57it/s]\n",
            "Loaded preprocessed cache from ./saved_labeled_node_interaction_indices/tgbn-genre_subset0.1_ts1135778006.0_seed42.npy\n",
            "100% 25461/25461 [00:00<00:00, 174782.40it/s]\n",
            "[FILTERED] Re-indexed 609 nodes:\n",
            "  - src_node_ids from [523, 1490] to [510, 608]\n",
            "  - dst_node_ids from [0, 512] to [0, 509]\n",
            "[DEBUG] edge_ids range: [1, 1667637]\n",
            "[DEBUG] edge_raw_features shape: (1667638, 1), max valid index: 1667637\n",
            "[DEBUG] src_node_ids range: [511, 609]\n",
            "[DEBUG] node_raw_features shape: (611, 1), max valid index: 610\n",
            "The dataset has 1667637 interactions, involving 609 different nodes\n",
            "The training dataset has 1185239 interactions, involving 592 different nodes\n",
            "The validation dataset has 240194 interactions, involving 575 different nodes\n",
            "The test dataset has 242204 interactions, involving 581 different nodes\n",
            "INFO:root:********** Run 1 starts. **********\n",
            "INFO:root:configuration is Namespace(dataset_name='tgbn-genre', batch_size=200, model_name='DyGFormer', gpu=0, num_neighbors=20, sample_neighbor_strategy='recent', time_scaling_factor=1e-06, num_walk_heads=8, num_heads=2, num_layers=2, walk_length=1, time_gap=2000, time_feat_dim=100, position_feat_dim=172, output_dim=172, moving_average_window_size=7, patch_size=8, channel_embedding_dim=50, max_input_sequence_length=256, learning_rate=0.0001, dropout=0.1, num_epochs=100, optimizer='Adam', weight_decay=0.0, patience=20, num_runs=5, test_interval_epochs=10, load_best_configs=True, subset_fraction=0.1, timestamp_threshold=1135778006.0, filter_seed=42, use_ma_features=True, ma_window_size=7, device='cuda:0', seed=0, save_model_name='DyGFormer_seed0')\n",
            "INFO:root:model -> Sequential(\n",
            "  (0): DyGFormer(\n",
            "    (time_encoder): TimeEncoder(\n",
            "      (w): Linear(in_features=1, out_features=100, bias=True)\n",
            "    )\n",
            "    (neighbor_co_occurrence_encoder): NeighborCooccurrenceEncoder(\n",
            "      (neighbor_co_occurrence_encode_layer): Sequential(\n",
            "        (0): Linear(in_features=1, out_features=50, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=50, out_features=50, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (projection_layer): ModuleDict(\n",
            "      (node): Linear(in_features=8, out_features=50, bias=True)\n",
            "      (edge): Linear(in_features=8, out_features=50, bias=True)\n",
            "      (time): Linear(in_features=800, out_features=50, bias=True)\n",
            "      (neighbor_co_occurrence): Linear(in_features=400, out_features=50, bias=True)\n",
            "    )\n",
            "    (transformers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoder(\n",
            "        (multi_head_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear_layers): ModuleList(\n",
            "          (0): Linear(in_features=200, out_features=800, bias=True)\n",
            "          (1): Linear(in_features=800, out_features=200, bias=True)\n",
            "        )\n",
            "        (norm_layers): ModuleList(\n",
            "          (0-1): 2 x LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_layer): Linear(in_features=200, out_features=172, bias=True)\n",
            "  )\n",
            "  (1): MLPClassifier(\n",
            "    (fc1): Linear(in_features=685, out_features=80, bias=True)\n",
            "    (fc2): Linear(in_features=80, out_features=10, bias=True)\n",
            "    (fc3): Linear(in_features=10, out_features=513, bias=True)\n",
            "    (act): ReLU()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "INFO:root:model name: DyGFormer, #parameters: 4499820 B, 4394.35546875 KB, 4.291362762451172 MB.\n",
            "INFO:root:MA Features enabled with window size: 7\n",
            "Epoch: 1, train for the 5919-th batch, train loss: 4.8555378913879395: 100%|████████| 5927/5927 [16:53<00:00,  5.85it/s]\n",
            "100% 933/933 [00:02<00:00, 349.43it/s]\n",
            "val for the 1201-th batch, loss: 4.890449047088623: 100%|███████████████████████████| 1201/1201 [02:04<00:00,  9.61it/s]\n",
            "100% 163/163 [00:00<00:00, 304.66it/s]\n",
            "INFO:root:Epoch: 1, learning rate: 0.0001, train loss: 5.0693\n",
            "INFO:root:train ndcg, 0.2705\n",
            "INFO:root:validate loss: 4.6825\n",
            "INFO:root:validate ndcg, 0.3341\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 2, train for the 5919-th batch, train loss: 4.7293572425842285: 100%|████████| 5927/5927 [16:56<00:00,  5.83it/s]\n",
            "100% 933/933 [00:02<00:00, 355.72it/s]\n",
            "val for the 1201-th batch, loss: 4.874362468719482: 100%|███████████████████████████| 1201/1201 [02:03<00:00,  9.74it/s]\n",
            "100% 163/163 [00:00<00:00, 330.72it/s]\n",
            "INFO:root:Epoch: 2, learning rate: 0.0001, train loss: 4.5850\n",
            "INFO:root:train ndcg, 0.3525\n",
            "INFO:root:validate loss: 4.6099\n",
            "INFO:root:validate ndcg, 0.3411\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 3, train for the 5919-th batch, train loss: 4.696325302124023: 100%|█████████| 5927/5927 [17:00<00:00,  5.81it/s]\n",
            "100% 933/933 [00:02<00:00, 325.73it/s]\n",
            "val for the 1201-th batch, loss: 4.876349449157715: 100%|███████████████████████████| 1201/1201 [02:06<00:00,  9.52it/s]\n",
            "100% 163/163 [00:00<00:00, 303.56it/s]\n",
            "INFO:root:Epoch: 3, learning rate: 0.0001, train loss: 4.5514\n",
            "INFO:root:train ndcg, 0.3575\n",
            "INFO:root:validate loss: 4.5989\n",
            "INFO:root:validate ndcg, 0.3396\n",
            "Epoch: 4, train for the 5919-th batch, train loss: 4.580550670623779: 100%|█████████| 5927/5927 [16:55<00:00,  5.84it/s]\n",
            "100% 933/933 [00:02<00:00, 349.08it/s]\n",
            "val for the 1201-th batch, loss: 4.877060890197754: 100%|███████████████████████████| 1201/1201 [02:03<00:00,  9.75it/s]\n",
            "100% 163/163 [00:00<00:00, 181.31it/s]\n",
            "INFO:root:Epoch: 4, learning rate: 0.0001, train loss: 4.5304\n",
            "INFO:root:train ndcg, 0.3607\n",
            "INFO:root:validate loss: 4.5921\n",
            "INFO:root:validate ndcg, 0.3397\n",
            "Epoch: 5, train for the 5919-th batch, train loss: 4.685519218444824: 100%|█████████| 5927/5927 [16:54<00:00,  5.84it/s]\n",
            "100% 933/933 [00:02<00:00, 349.12it/s]\n",
            "val for the 1201-th batch, loss: 4.878354072570801: 100%|███████████████████████████| 1201/1201 [02:03<00:00,  9.76it/s]\n",
            "100% 163/163 [00:00<00:00, 263.31it/s]\n",
            "INFO:root:Epoch: 5, learning rate: 0.0001, train loss: 4.5169\n",
            "INFO:root:train ndcg, 0.3652\n",
            "INFO:root:validate loss: 4.5848\n",
            "INFO:root:validate ndcg, 0.3429\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 6, train for the 5919-th batch, train loss: 4.643886566162109: 100%|█████████| 5927/5927 [16:59<00:00,  5.81it/s]\n",
            "100% 933/933 [00:02<00:00, 339.91it/s]\n",
            "val for the 1201-th batch, loss: 4.872365474700928: 100%|███████████████████████████| 1201/1201 [02:04<00:00,  9.61it/s]\n",
            "100% 163/163 [00:00<00:00, 184.76it/s]\n",
            "INFO:root:Epoch: 6, learning rate: 0.0001, train loss: 4.5020\n",
            "INFO:root:train ndcg, 0.3671\n",
            "INFO:root:validate loss: 4.5779\n",
            "INFO:root:validate ndcg, 0.3453\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 7, train for the 5919-th batch, train loss: 4.591943740844727: 100%|█████████| 5927/5927 [16:57<00:00,  5.82it/s]\n",
            "100% 933/933 [00:02<00:00, 320.81it/s]\n",
            "val for the 1201-th batch, loss: 4.855419158935547: 100%|███████████████████████████| 1201/1201 [02:04<00:00,  9.63it/s]\n",
            "100% 163/163 [00:00<00:00, 188.90it/s]\n",
            "INFO:root:Epoch: 7, learning rate: 0.0001, train loss: 4.4886\n",
            "INFO:root:train ndcg, 0.3705\n",
            "INFO:root:validate loss: 4.5666\n",
            "INFO:root:validate ndcg, 0.3573\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 8, train for the 5919-th batch, train loss: 4.567779541015625: 100%|█████████| 5927/5927 [16:53<00:00,  5.85it/s]\n",
            "100% 933/933 [00:03<00:00, 260.36it/s]\n",
            "val for the 1201-th batch, loss: 4.808849334716797: 100%|███████████████████████████| 1201/1201 [02:04<00:00,  9.66it/s]\n",
            "100% 163/163 [00:00<00:00, 275.15it/s]\n",
            "INFO:root:Epoch: 8, learning rate: 0.0001, train loss: 4.4665\n",
            "INFO:root:train ndcg, 0.3761\n",
            "INFO:root:validate loss: 4.5479\n",
            "INFO:root:validate ndcg, 0.3618\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 9, train for the 5919-th batch, train loss: 4.506107807159424: 100%|█████████| 5927/5927 [16:47<00:00,  5.88it/s]\n",
            "100% 933/933 [00:02<00:00, 343.60it/s]\n",
            "val for the 1201-th batch, loss: 4.735007286071777: 100%|███████████████████████████| 1201/1201 [02:05<00:00,  9.57it/s]\n",
            "100% 163/163 [00:00<00:00, 290.27it/s]\n",
            "INFO:root:Epoch: 9, learning rate: 0.0001, train loss: 4.4337\n",
            "INFO:root:train ndcg, 0.3841\n",
            "INFO:root:validate loss: 4.5204\n",
            "INFO:root:validate ndcg, 0.3758\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 10, train for the 5919-th batch, train loss: 4.48482084274292: 100%|█████████| 5927/5927 [16:54<00:00,  5.84it/s]\n",
            "100% 933/933 [00:02<00:00, 353.18it/s]\n",
            "val for the 1201-th batch, loss: 4.653273582458496: 100%|███████████████████████████| 1201/1201 [02:00<00:00,  9.95it/s]\n",
            "100% 163/163 [00:00<00:00, 334.02it/s]\n",
            "INFO:root:Epoch: 10, learning rate: 0.0001, train loss: 4.3967\n",
            "INFO:root:train ndcg, 0.3947\n",
            "INFO:root:validate loss: 4.4900\n",
            "INFO:root:validate ndcg, 0.3843\n",
            "test for the 1203-th batch, loss: 4.957462310791016: 100%|██████████████████████████| 1212/1212 [01:57<00:00, 10.34it/s]\n",
            "100% 166/166 [00:00<00:00, 356.24it/s]\n",
            "INFO:root:test loss: 4.5147\n",
            "INFO:root:test ndcg, 0.4046\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 11, train for the 5919-th batch, train loss: 4.369901657104492: 100%|████████| 5927/5927 [16:45<00:00,  5.89it/s]\n",
            "100% 933/933 [00:03<00:00, 287.59it/s]\n",
            "val for the 1201-th batch, loss: 4.5797529220581055: 100%|██████████████████████████| 1201/1201 [02:02<00:00,  9.78it/s]\n",
            "100% 163/163 [00:00<00:00, 308.39it/s]\n",
            "INFO:root:Epoch: 11, learning rate: 0.0001, train loss: 4.3656\n",
            "INFO:root:train ndcg, 0.4009\n",
            "INFO:root:validate loss: 4.4618\n",
            "INFO:root:validate ndcg, 0.3893\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 12, train for the 5919-th batch, train loss: 4.358649253845215: 100%|████████| 5927/5927 [16:51<00:00,  5.86it/s]\n",
            "100% 933/933 [00:02<00:00, 337.50it/s]\n",
            "val for the 1201-th batch, loss: 4.517465591430664: 100%|███████████████████████████| 1201/1201 [02:03<00:00,  9.76it/s]\n",
            "100% 163/163 [00:00<00:00, 316.18it/s]\n",
            "INFO:root:Epoch: 12, learning rate: 0.0001, train loss: 4.3340\n",
            "INFO:root:train ndcg, 0.4050\n",
            "INFO:root:validate loss: 4.4411\n",
            "INFO:root:validate ndcg, 0.3912\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 13, train for the 5919-th batch, train loss: 4.317788600921631: 100%|████████| 5927/5927 [16:47<00:00,  5.88it/s]\n",
            "100% 933/933 [00:03<00:00, 257.24it/s]\n",
            "val for the 1201-th batch, loss: 4.4830522537231445: 100%|██████████████████████████| 1201/1201 [02:01<00:00,  9.86it/s]\n",
            "100% 163/163 [00:00<00:00, 314.31it/s]\n",
            "INFO:root:Epoch: 13, learning rate: 0.0001, train loss: 4.3099\n",
            "INFO:root:train ndcg, 0.4092\n",
            "INFO:root:validate loss: 4.4278\n",
            "INFO:root:validate ndcg, 0.3914\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 14, train for the 5919-th batch, train loss: 4.291308403015137: 100%|████████| 5927/5927 [16:51<00:00,  5.86it/s]\n",
            "100% 933/933 [00:02<00:00, 350.42it/s]\n",
            "val for the 1201-th batch, loss: 4.448689937591553: 100%|███████████████████████████| 1201/1201 [02:03<00:00,  9.75it/s]\n",
            "100% 163/163 [00:00<00:00, 314.13it/s]\n",
            "INFO:root:Epoch: 14, learning rate: 0.0001, train loss: 4.2899\n",
            "INFO:root:train ndcg, 0.4125\n",
            "INFO:root:validate loss: 4.4142\n",
            "INFO:root:validate ndcg, 0.3944\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 15, train for the 5919-th batch, train loss: 4.501668930053711: 100%|████████| 5927/5927 [17:07<00:00,  5.77it/s]\n",
            "100% 933/933 [00:03<00:00, 299.91it/s]\n",
            "val for the 1201-th batch, loss: 4.425245761871338: 100%|███████████████████████████| 1201/1201 [02:05<00:00,  9.54it/s]\n",
            "100% 163/163 [00:00<00:00, 256.46it/s]\n",
            "INFO:root:Epoch: 15, learning rate: 0.0001, train loss: 4.2765\n",
            "INFO:root:train ndcg, 0.4135\n",
            "INFO:root:validate loss: 4.4060\n",
            "INFO:root:validate ndcg, 0.3952\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 16, train for the 5919-th batch, train loss: 4.331851959228516: 100%|████████| 5927/5927 [17:10<00:00,  5.75it/s]\n",
            "100% 933/933 [00:02<00:00, 335.33it/s]\n",
            "val for the 1201-th batch, loss: 4.412014007568359: 100%|███████████████████████████| 1201/1201 [02:08<00:00,  9.32it/s]\n",
            "100% 163/163 [00:00<00:00, 290.75it/s]\n",
            "INFO:root:Epoch: 16, learning rate: 0.0001, train loss: 4.2604\n",
            "INFO:root:train ndcg, 0.4173\n",
            "INFO:root:validate loss: 4.3932\n",
            "INFO:root:validate ndcg, 0.3964\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 17, train for the 5919-th batch, train loss: 4.37351655960083: 100%|█████████| 5927/5927 [17:13<00:00,  5.74it/s]\n",
            "100% 933/933 [00:03<00:00, 296.97it/s]\n",
            "val for the 1201-th batch, loss: 4.396717071533203: 100%|███████████████████████████| 1201/1201 [02:07<00:00,  9.42it/s]\n",
            "100% 163/163 [00:00<00:00, 307.42it/s]\n",
            "INFO:root:Epoch: 17, learning rate: 0.0001, train loss: 4.2464\n",
            "INFO:root:train ndcg, 0.4212\n",
            "INFO:root:validate loss: 4.3846\n",
            "INFO:root:validate ndcg, 0.3984\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 18, train for the 5919-th batch, train loss: 4.438267707824707: 100%|████████| 5927/5927 [17:08<00:00,  5.77it/s]\n",
            "100% 933/933 [00:03<00:00, 255.60it/s]\n",
            "val for the 1201-th batch, loss: 4.389585494995117: 100%|███████████████████████████| 1201/1201 [02:07<00:00,  9.42it/s]\n",
            "100% 163/163 [00:00<00:00, 289.35it/s]\n",
            "INFO:root:Epoch: 18, learning rate: 0.0001, train loss: 4.2310\n",
            "INFO:root:train ndcg, 0.4257\n",
            "INFO:root:validate loss: 4.3714\n",
            "INFO:root:validate ndcg, 0.4010\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 19, train for the 5919-th batch, train loss: 4.329597473144531: 100%|████████| 5927/5927 [17:17<00:00,  5.71it/s]\n",
            "100% 933/933 [00:02<00:00, 336.37it/s]\n",
            "val for the 1201-th batch, loss: 4.375936031341553: 100%|███████████████████████████| 1201/1201 [02:07<00:00,  9.40it/s]\n",
            "100% 163/163 [00:00<00:00, 294.68it/s]\n",
            "INFO:root:Epoch: 19, learning rate: 0.0001, train loss: 4.2195\n",
            "INFO:root:train ndcg, 0.4303\n",
            "INFO:root:validate loss: 4.3578\n",
            "INFO:root:validate ndcg, 0.4073\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 20, train for the 5919-th batch, train loss: 4.273101806640625: 100%|████████| 5927/5927 [17:13<00:00,  5.74it/s]\n",
            "100% 933/933 [00:02<00:00, 327.84it/s]\n",
            "val for the 1201-th batch, loss: 4.36402702331543: 100%|████████████████████████████| 1201/1201 [02:08<00:00,  9.37it/s]\n",
            "100% 163/163 [00:00<00:00, 295.17it/s]\n",
            "INFO:root:Epoch: 20, learning rate: 0.0001, train loss: 4.1998\n",
            "INFO:root:train ndcg, 0.4346\n",
            "INFO:root:validate loss: 4.3426\n",
            "INFO:root:validate ndcg, 0.4140\n",
            "test for the 1203-th batch, loss: 4.403698921203613: 100%|██████████████████████████| 1212/1212 [02:03<00:00,  9.82it/s]\n",
            "100% 166/166 [00:00<00:00, 191.95it/s]\n",
            "INFO:root:test loss: 4.3896\n",
            "INFO:root:test ndcg, 0.4329\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 21, train for the 5919-th batch, train loss: 4.3308563232421875: 100%|███████| 5927/5927 [17:17<00:00,  5.71it/s]\n",
            "100% 933/933 [00:02<00:00, 325.71it/s]\n",
            "val for the 1201-th batch, loss: 4.349055290222168: 100%|███████████████████████████| 1201/1201 [02:09<00:00,  9.31it/s]\n",
            "100% 163/163 [00:00<00:00, 298.19it/s]\n",
            "INFO:root:Epoch: 21, learning rate: 0.0001, train loss: 4.1797\n",
            "INFO:root:train ndcg, 0.4401\n",
            "INFO:root:validate loss: 4.3291\n",
            "INFO:root:validate ndcg, 0.4175\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 22, train for the 5919-th batch, train loss: 4.231221675872803: 100%|████████| 5927/5927 [17:10<00:00,  5.75it/s]\n",
            "100% 933/933 [00:04<00:00, 227.40it/s]\n",
            "val for the 1201-th batch, loss: 4.339084625244141: 100%|███████████████████████████| 1201/1201 [02:06<00:00,  9.47it/s]\n",
            "100% 163/163 [00:00<00:00, 296.81it/s]\n",
            "INFO:root:Epoch: 22, learning rate: 0.0001, train loss: 4.1689\n",
            "INFO:root:train ndcg, 0.4434\n",
            "INFO:root:validate loss: 4.3126\n",
            "INFO:root:validate ndcg, 0.4233\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 23, train for the 5919-th batch, train loss: 4.261716365814209: 100%|████████| 5927/5927 [17:09<00:00,  5.76it/s]\n",
            "100% 933/933 [00:03<00:00, 306.22it/s]\n",
            "val for the 1201-th batch, loss: 4.333690643310547: 100%|███████████████████████████| 1201/1201 [02:04<00:00,  9.66it/s]\n",
            "100% 163/163 [00:00<00:00, 305.83it/s]\n",
            "INFO:root:Epoch: 23, learning rate: 0.0001, train loss: 4.1547\n",
            "INFO:root:train ndcg, 0.4457\n",
            "INFO:root:validate loss: 4.3033\n",
            "INFO:root:validate ndcg, 0.4249\n",
            "INFO:root:save model ./saved_models/DyGFormer/tgbn-genre/DyGFormer_seed0/DyGFormer_seed0.pkl\n",
            "Epoch: 24, train for the 2591-th batch, train loss: 4.238872528076172:  44%|███▍    | 2591/5927 [07:29<09:38,  5.76it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/tgbn-project/train_node_classification.py\", line 230, in <module>\n",
            "    model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,\n",
            "  File \"/content/tgbn-project/models/DyGFormer.py\", line 107, in compute_src_dst_node_temporal_embeddings\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/tgbn-project/models/DyGFormer.py\", line 406, in forward\n",
            "    src_padded_nodes_appearances, dst_padded_nodes_appearances = self.count_nodes_appearances(src_padded_nodes_neighbor_ids=src_padded_nodes_neighbor_ids,\n",
            "                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/tgbn-project/models/DyGFormer.py\", line 356, in count_nodes_appearances\n",
            "    src_unique_keys, src_inverse_indices, src_counts = np.unique(src_padded_node_neighbor_ids, return_inverse=True, return_counts=True)\n",
            "                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/_arraysetops_impl.py\", line 289, in unique\n",
            "    ret = _unique1d(ar, return_index, return_inverse, return_counts, \n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/_arraysetops_impl.py\", line 378, in _unique1d\n",
            "    imask = np.cumsum(mask) - 1\n",
            "            ^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}