{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization through shallow embeddings"
      ],
      "metadata": {
        "id": "NQ2Rt8yqcQgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is partially inspired from the paper De Nadai, M., et al, Personalized Audiobook Recommendations at Spotify Through Graph Neural Networks.\n",
        "  WWW '24: Companion Proceedings of the ACM Web Conference 2024, ACM (2024), pp. 403--412, 2024."
      ],
      "metadata": {
        "id": "4QrqjDPSIsgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INSTALLATION AND IMPORTS ---\n",
        "!pip install pandas -q\n",
        "!pip install torch-geometric -f https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
        "!pip install py-tgb -q\n",
        "!pip install modules\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.loader import TemporalDataLoader\n",
        "from torch_geometric.nn.models.tgn import LastNeighborLoader\n",
        "from tgb.nodeproppred.dataset_pyg import PyGNodePropPredDataset\n",
        "from tgb.nodeproppred.evaluate import Evaluator\n",
        "from tgb.utils.utils import set_random_seed\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from tqdm import tqdm\n",
        "import timeit\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- CONFIGURATION CONSTANTS ---\n",
        "SEED = 1\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_GENRES = 264\n",
        "NB_NEIGHBORS = 10\n",
        "LR_MAIN = 1e-3\n",
        "LR_PRETRAIN = 0.01\n",
        "EPOCHS_MAIN = 10\n",
        "EPOCHS_PRETRAIN = 100\n",
        "CO_OCCURRENCE_THRESHOLD = 0.3\n",
        "FINETUNE_EMBEDDINGS = True # Set to False to freeze embeddings\n",
        "PRETRAINED_EMB_PATH = \"pretrained_genre_embeddings.pt\" #the path to the created embeddings\n",
        "# --- END CONFIGURATION ---\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(SEED)\n",
        "set_random_seed(SEED)\n",
        "print(\"Setting random seed to\", SEED)\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# --- UTILITY CLASSES ---\n",
        "\n",
        "class NodePredictor(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.lin_node = Linear(in_dim, in_dim)\n",
        "        self.out = Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, node_embed):\n",
        "        h = self.lin_node(node_embed)\n",
        "        h = F.relu(h)\n",
        "        h = self.out(h)\n",
        "        return h\n",
        "\n",
        "class StaticEmbeddingMemory(nn.Module):\n",
        "    \"\"\"\n",
        "    Core Embedding layer for the main model.\n",
        "    It handles loading pretrained weights or initializing randomly.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_nodes, emb_dim, pretrained_path=None, freeze=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Default random initialization (Xavier uniform)\n",
        "        self.emb = nn.Embedding(num_nodes, emb_dim)\n",
        "        nn.init.xavier_uniform_(self.emb.weight)\n",
        "\n",
        "        # Load and potentially freeze pretrained weights\n",
        "        if pretrained_path and os.path.exists(pretrained_path):\n",
        "            pretrained_weights = torch.load(pretrained_path).to(DEVICE)\n",
        "            if pretrained_weights.shape == (num_nodes, emb_dim):\n",
        "                print(f\"Loaded pretrained embeddings from {pretrained_path}.\")\n",
        "                self.emb = nn.Embedding.from_pretrained(pretrained_weights, freeze=freeze)\n",
        "            else:\n",
        "                print(f\"Warning: Pretrained weights shape {pretrained_weights.shape} mismatch. Initializing randomly.\")\n",
        "        else:\n",
        "            print(f\"No valid pretrained embeddings found. Initializing randomly.\")\n",
        "\n",
        "    def forward(self, n_id):\n",
        "        return self.emb(n_id)\n",
        "\n",
        "    def update_state(self, *args, **kwargs):\n",
        "        return\n",
        "    def reset_state(self):\n",
        "        return\n",
        "    def detach(self):\n",
        "        return\n",
        "\n",
        "class SimpleGCN(nn.Module):\n",
        "    \"\"\"2-layer GCN encoder for the main model.\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "def reset_all_label_pointers(ds):\n",
        "    for name in [\"_label_time_idx\", \"label_time_idx\", \"_current_label_idx\"]:\n",
        "        if hasattr(ds, name):\n",
        "            try:\n",
        "                setattr(ds, name, 0)\n",
        "            except Exception:\n",
        "                pass\n",
        "    for split in [\"train\", \"valid\", \"val\", \"test\"]:\n",
        "        for name in [f\"_{split}_label_time_idx\", f\"{split}_label_time_idx\"]:\n",
        "            if hasattr(ds, name):\n",
        "                try:\n",
        "                    setattr(ds, name, 0)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "def rebuild_dataset_and_loaders(dataset, data, train_mask, val_mask, test_mask, batch_size, device):\n",
        "    _ds = PyGNodePropPredDataset(name=dataset.name, root=\"datasets\")\n",
        "    _data = _ds.get_TemporalData().to(device)\n",
        "\n",
        "    _train_data = _data[train_mask].to(device)\n",
        "    _val_data   = _data[val_mask].to(device)\n",
        "    _test_data  = _data[test_mask].to(device)\n",
        "\n",
        "    _train_loader = TemporalDataLoader(_train_data, batch_size=batch_size, shuffle=False)\n",
        "    _val_loader   = TemporalDataLoader(_val_data,   batch_size=batch_size, shuffle=False)\n",
        "    _test_loader  = TemporalDataLoader(_test_data,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return _ds, _data, _train_data, _val_data, _test_data, _train_loader, _val_loader, _test_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXrQ94xFkjoC",
        "outputId": "ca0b5e5a-7783-4573-8637-8292d28edd73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Requirement already satisfied: modules in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Setting random seed to 1\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GRAPH BUILDING (STREAMING LABELS)\n",
        "print(\"\\n--- 1. Building Static Genre Co-occurrence Graph via Streaming ---\")\n",
        "\n",
        "if 'dataset' not in locals():\n",
        "    name = \"tgbn-genre\"\n",
        "    dataset = PyGNodePropPredDataset(name=name, root=\"datasets\")\n",
        "\n",
        "if 'full_data' not in locals():\n",
        "    full_data = dataset.get_TemporalData()\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# Data Loaders\n",
        "train_loader_full = TemporalDataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader_full = TemporalDataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader_full = TemporalDataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def stream_and_collect_labels(loader, split_name):\n",
        "    \"\"\"Streams data using TGB's causal mechanism and collects all resulting labels.\"\"\"\n",
        "    print(f\"Streaming {split_name} split...\")\n",
        "\n",
        "    # reset internal label pointer\n",
        "    dataset.reset_label_time()\n",
        "    label_t = dataset.get_label_time()\n",
        "\n",
        "    all_labels_list = []\n",
        "\n",
        "    for batch in tqdm(loader):\n",
        "        query_t = batch.t[-1]\n",
        "\n",
        "        if query_t > label_t:\n",
        "            label_tuple = dataset.get_node_label(query_t)\n",
        "\n",
        "            if label_tuple is None:\n",
        "                continue\n",
        "\n",
        "            label_ts, label_srcs, labels = label_tuple\n",
        "            label_t = dataset.get_label_time() # Get next label timestamp\n",
        "\n",
        "            all_labels_list.append(labels.cpu())\n",
        "\n",
        "    # Return concatenated 2D tensor (N_labeled_events, N_genres)\n",
        "    return torch.cat(all_labels_list, dim=0) if all_labels_list else torch.empty((0, NUM_GENRES))\n",
        "\n",
        "# Accumulate labels from all splits\n",
        "all_labels_list = []\n",
        "all_labels_list.append(stream_and_collect_labels(train_loader_full, \"Train\"))\n",
        "all_labels_list.append(stream_and_collect_labels(val_loader_full, \"Validation\"))\n",
        "all_labels_list.append(stream_and_collect_labels(test_loader_full, \"Test\"))\n",
        "\n",
        "all_labels = torch.cat(all_labels_list, dim=0)\n",
        "\n",
        "if all_labels.shape[1] > NUM_GENRES:\n",
        "     print(f\"WARNING: Slicing label matrix from {all_labels.shape[1]} columns down to {NUM_GENRES} columns.\")\n",
        "     all_labels = all_labels[:, :NUM_GENRES]\n",
        "\n",
        "if all_labels.shape[1] != NUM_GENRES:\n",
        "    raise RuntimeError(f\"Label matrix must have {NUM_GENRES} columns. Found {all_labels.shape[1]}. Cannot proceed.\")\n",
        "\n",
        "num_genres = all_labels.shape[1]\n",
        "print(f\"Total Labeled Events extracted via streaming: {all_labels.size(0)}\")\n",
        "\n",
        "\n",
        "# Filter out empty label vectors, if any, if needed\n",
        "valid_labels = all_labels[torch.sum(all_labels, dim=1) > 0]\n",
        "if valid_labels.size(0) == 0:\n",
        "    raise RuntimeError(\"The dataset appears to contain no valid labeled events (data.y is all zeros or empty). Cannot build co-occurrence graph.\")\n",
        "\n",
        "# Build the Co-occurrence Matrix to filter then\n",
        "label_tensor = valid_labels.float()\n",
        "co_occurrence_matrix = torch.matmul(label_tensor.T, label_tensor).cpu().numpy()\n",
        "\n",
        "# Build Adjacency Matrix using the threshold\n",
        "N = np.diag(co_occurrence_matrix)\n",
        "epsilon = 1e-8\n",
        "N_i = N.reshape(-1, 1) + epsilon\n",
        "N_j = N.reshape(1, -1) + epsilon\n",
        "ratio_i = co_occurrence_matrix / N_i\n",
        "ratio_j = co_occurrence_matrix / N_j\n",
        "adjacency_matrix = np.logical_or(ratio_i >= CO_OCCURRENCE_THRESHOLD, ratio_j >= CO_OCCURRENCE_THRESHOLD).astype(int)\n",
        "np.fill_diagonal(adjacency_matrix, 0)\n",
        "\n",
        "# Convert to PyTorch Geometric Graph Object\n",
        "coo_adj = sp.coo_matrix(adjacency_matrix)\n",
        "edge_index = torch.tensor(np.vstack([coo_adj.row, coo_adj.col]), dtype=torch.long)\n",
        "initial_x = nn.Embedding(NUM_GENRES, EMBEDDING_DIM).weight.data\n",
        "genre_graph = Data(x=initial_x, edge_index=edge_index, num_nodes=NUM_GENRES).to(DEVICE)\n",
        "\n",
        "print(f\"Genre Nodes: {NUM_GENRES}, Edges (Undirected): {edge_index.size(1) // 2}\")\n",
        "print(f\"Co-occurrence Threshold: {CO_OCCURRENCE_THRESHOLD}\")\n",
        "\n",
        "# 2. DEFINING THE SHALLOW EMBEDDING MODEL\n",
        "\n",
        "class ShallowGCNEncoder(nn.Module):\n",
        "    def __init__(self, num_nodes, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_nodes, in_channels)\n",
        "        nn.init.xavier_uniform_(self.embedding.weight)\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "    def forward(self, node_ids, edge_index):\n",
        "        x = self.embedding(node_ids)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "def dot_product_loss(z, pos_edge_index, neg_edge_index):\n",
        "    pos_score = torch.sum(z[pos_edge_index[0]] * z[pos_edge_index[1]], dim=1)\n",
        "    neg_score = torch.sum(z[neg_edge_index[0]] * z[neg_edge_index[1]], dim=1)\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    targets = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
        "    return F.binary_cross_entropy_with_logits(scores, targets)\n",
        "\n",
        "def negative_sample_edges(num_nodes, pos_edge_index, num_neg_samples):\n",
        "    neg_edges = torch.randint(0, num_nodes, (2, num_neg_samples), dtype=torch.long, device=DEVICE)\n",
        "    return neg_edges\n",
        "\n",
        "# 3. EMBEDDING TRAINING AND SAVING\n",
        "\n",
        "genre_encoder = ShallowGCNEncoder(\n",
        "    num_nodes=NUM_GENRES,\n",
        "    in_channels=EMBEDDING_DIM,\n",
        "    hidden_channels=EMBEDDING_DIM,\n",
        "    out_channels=EMBEDDING_DIM\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer_pretrain = torch.optim.Adam(genre_encoder.parameters(), lr=LR_PRETRAIN)\n",
        "pos_edge_index = genre_graph.edge_index.to(DEVICE)\n",
        "all_node_ids = torch.arange(NUM_GENRES, device=DEVICE)\n",
        "num_neg_samples = pos_edge_index.size(1)\n",
        "\n",
        "print(f\"\\n--- 3. Starting Shallow GNN Pre-training ({EPOCHS_PRETRAIN} Epochs) ---\")\n",
        "\n",
        "for epoch in range(1, EPOCHS_PRETRAIN + 1):\n",
        "    genre_encoder.train()\n",
        "    optimizer_pretrain.zero_grad()\n",
        "\n",
        "    z = genre_encoder(all_node_ids, pos_edge_index)\n",
        "    neg_edge_index = negative_sample_edges(NUM_GENRES, pos_edge_index, num_neg_samples)\n",
        "    loss = dot_product_loss(z, pos_edge_index, neg_edge_index)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer_pretrain.step()\n",
        "\n",
        "    if epoch % 20 == 0 or epoch == EPOCHS_PRETRAIN:\n",
        "        print(f\"Epoch {epoch:03d}/{EPOCHS_PRETRAIN}: Loss = {loss.item():.6f}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    genre_encoder.eval()\n",
        "    pretrained_embeddings = genre_encoder.embedding.weight.data.clone().cpu()\n",
        "    torch.save(pretrained_embeddings, PRETRAINED_EMB_PATH)\n",
        "\n",
        "print(f\"\\nPre-training Complete. Embeddings saved to: {PRETRAINED_EMB_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hat837Rgkjq2",
        "outputId": "5acbc6e1-27fe-4b00-8356-15a005d3c385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. Building Static Genre Co-occurrence Graph via Streaming ---\n",
            "Streaming Train split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250088/1250088 [06:52<00:00, 3029.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming Validation split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267876/267876 [01:27<00:00, 3054.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming Test split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267876/267876 [01:27<00:00, 3046.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Slicing label matrix from 513 columns down to 264 columns.\n",
            "Total Labeled Events extracted via streaming: 668557\n",
            "Genre Nodes: 264, Edges (Undirected): 341\n",
            "Co-occurrence Threshold: 0.3\n",
            "\n",
            "--- 3. Starting Shallow GNN Pre-training (100 Epochs) ---\n",
            "Epoch 020/100: Loss = 0.432593\n",
            "Epoch 040/100: Loss = 0.418416\n",
            "Epoch 060/100: Loss = 0.394377\n",
            "Epoch 080/100: Loss = 0.395304\n",
            "Epoch 100/100: Loss = 0.408549\n",
            "\n",
            "Pre-training Complete. Embeddings saved to: pretrained_genre_embeddings.pt\n"
          ]
        }
      ]
    }
  ]
}